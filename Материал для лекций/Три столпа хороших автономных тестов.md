# Три столпа хороших автономных тестов

В этой главе:
 - Написание заслуживающих доверия тестов.
 - Написание удобных для сопровождения тестов.
 - Написание удобочитаемых тестов.
 - Соглашения об именовании автономных тестов.


Как бы вы ни организовывали свои тесты и сколько бы их ни было,
грош им цена, если им нельзя доверять, неудобно сопровождать или
невозможно читать. Чтобы тест считался хорошим, он должен обладать тремя свойствами.

- Высокая степень доверия. Разработчики хотят, чтобы результатам тестов можно было доверять. В заслуживающих доверия
тестах нет ошибок, и они тестируют именно то, что надо.

- Удобство сопровождения. Непригодные для сопровождения
тесты – сущий кошмар, потому что из-за них срываются сроки,
а если график работ над проектом ужесточается, то их просто
откладывают в сторонку. Разработчики перестают сопровождать и исправлять тесты, которые слишком долго изменять
или приходится модифицировать при малейшем изменении
продуктового кода.

- Удобочитаемость. Это означает, что тест легко не только прочитать, но и понять, в чем проблема, если он выдает странные
результаты. Без удобочитаемости два остальных столпа очень
быстро подламываются. Сопровождать тесты становится труднее, а доверять тому, чего не понимаешь, невозможно.

В этой главе даются рекомендации по каждому из этих столпов. Вы
можете использовать их в ходе анализа тестов. В совокупности эти
три столпа гарантируют, что вы не зря тратите время. Уберите любой
из них – и появится риск, что все, что вы делаете, пойдет насмарку.


## Написание заслуживающих доверия тестов

О том, заслуживает ли тест доверия, можно судить по нескольким
признакам. Если тест проходит, вы не говорите себе: «А пройду-ка я
этот код в отладчике, чтобы уж наверняка». Вы верите, что раз тест
прошел, то тестируемый код в конкретном случае работает правильно. Если тест не проходит, вы не говорите себе: «А, да он и не должен был пройти» или «Это еще не значит, что код не работает». Вы
верите, что ошибка именно в коде, а не в тесте. Короче говоря, тест
достоин доверия, если вы уверены, что знаете, что происходит и как
можно вмешаться.

В этой главе я дам некоторые рекомендации и опишу приемы, которые помогут вам:

- принять решение о том, когда удалять или изменять тесты;
- избежать наличия логики в тестах;
- тестировать только один результат;
- разделять автономные и интеграционные тесты;
- уделять критическому анализу кода столько же внимания, сколько покрытию кода тестами.

По моему опыту, тесты, следующие этим рекомендациям, в большей мере заслуживают доверия; я чувствую уверенность, что они и
дальше будут находить ошибки в моем коде.


## Когда удалять или изменять тесты

Написав тесты и добившись того, что они проходят, мы, вообще говоря, не должны ни удалять, ни изменять их. Это страховочная сетка,
благодаря которой мы узнаем, что очередная модификация кода привела к поломке. Тем не менее, бывают случаи, когда мы вынуждены
удалять или изменять имеющиеся тесты. Чтобы понять, когда это
имеет смысл, рассмотрим причины того и другого. Почему удаляется
тест? Главным образом, потому что он не проходит. Перечислим возможные причины внезапного отказа теста.

- Ошибки в продуктовом коде. В тестируемом продуктовом коде
имеется ошибка.
- Ошибки в тесте. В тесте имеется ошибка.
- Изменение семантики или API. Изменилась семантика, но не
функциональность тестируемого кода
- Конфликтующие или недействительные тесты. Продуктовый
код был изменен с целью удовлетворения требования, противоречащего предыдущим.

Для удаления или изменения тестов есть также причины, не связанные с ошибками в коде или тесте:

- чтобы переименовать или переработать тест;
- чтобы исключить дублирующиеся тесты.

Рассмотрим каждый из этих случаев.

## Ошибки в продуктовом коде

Ошибка в продуктовом коде имеет место, когда после изменения
продуктового кода какой-то тест перестает проходить. Если это действительно ошибка в тестируемом коде, то с тестом все в порядке и
трогать его не нужно. Это наилучший и желательный результат, ради
которого тесты и пишутся.
Поскольку обнаружение ошибок в продуктовом коде и есть цель
автономного тестирования, то остается только исправить эту ошибку.
Тест не трогайте.

## Ошибки в тесте

Если ошибка вкралась в тест, то тест необходимо изменить. Ошибки в тестах особенно трудно искать, потому что предполагается, что
тесты правильны. (Именно поэтому я так люблю TDD. Это дополнительный способ протестировать сам тест и убедиться, что он падает и проходит именно тогда, когда должен.) Я наблюдал несколько
стадий, через которые проходят разработчики, обнаружив ошибку в
тесте.

1. Отрицание. Разработчик продолжает искать ошибку в самом
коде, изменяет его, в результате чего перестают работать все остальные тесты. Разработчик вносит в продуктовый код новые
ошибки, охотясь за той, что на самом деле находится в тесте.

2. Развлечение. Если есть возможность, разработчик зовет коллегу, и они вместе продолжают искать несуществующую ошибку
3. Отладка. Разработчик терпеливо отлаживает тест и обнаруживает, что ошибка затесалась в тест. На это может уйти от
часа до нескольких дней.
4. Признание и битье головой об стенку. Разработчик наконец
осознает, где ошибка, и начинает лупить себя по лбу.

Обнаружив и начав исправлять ошибку, убедитесь, что ошибка
действительно исправлена и что тест волшебным образом проходит
не потому, что вы тестируете что-то совсем другое. Необходимо сделать следующее:
1. Исправить ошибку в тесте
2. Проверить, что тест падает, когда должен падать.
3. Проверить, что тест проходит, когда должен проходить.

Первый шаг – исправление ошибки в тесте – затруднений не вызывает. А дальше нужно убедиться, что тестируется то, что надо, и что
тесту по-прежнему можно доверять.
Исправив тест, переходите к продуктовому коду и измените его
так, чтобы проявилась ошибка, которую тест должен отловить. Например, для этого может понадобиться закомментировать какую-нибудь строку или изменить булево значение. Затем выполните тест.
Если тест падает, значит, он наполовину работает. Вторая половина
проверяется на шаге 3. Если тест не падает, значит, вы, скорее всего, тестируете не то, что надо. (Я видел, как разработчики случайно
удаляли из теста утверждения в ходе исправления ошибки. Вы не поверите, как часто такое случается и насколько эффективным в таких
случаях оказывается шаг 2.)
Убедившись, что тест падает, уберите ошибку из продуктового
кода. Теперь тест должен проходить. Если это не так, то либо ошибка
в тесте осталась, либо вы тестируете что-то не то. Обязательно нужно
добиться, чтобы тест сначала не прошел, а потом – после устранения
ошибки – снова прошел.

## Изменение семантики или API

Тест может отказать, если продуктовый код изменяется таким образом, что тестируемый объект должен использоваться по-другому,
пусть даже его конечная функциональность сохраняется.
В листинге ниже приведен простой тест.

Листинг 8.1. Простой тест класса LogAnalyzer

```C#

[Test]
public void SemanticsChange()

{
 LogAnalyzer logan = new LogAnalyzer();
 Assert.IsFalse(logan.IsValid(“abc”));
}

```

Предположим, что мы изменили семантику класса LogAnalyzer,
добавив метод Initialize. Теперь до вызова любого метода класса
LogAnalyzer необходимо инициализировать его путем обращения к
методу Initialize .

Если внести такое изменение в продуктовый код, то утверждение в
листинге 8.1 возбудит исключение, потому что метод Initialize не
вызывался. Тест не пройдет, хотя он по-прежнему корректный. Проверяемая им функциональность работает, но семантика тестируемого
объекта изменилась.

В этом случае тест необходимо привести в соответствие с новой
семантикой, как показано ниже.

Листинг 8.2. Тест класса LogAnalyzer после приведения
в соответствие с новой семантикой

```C#

[Test]
public void SemanticsChange()
{
 LogAnalyzer logan = new LogAnalyzer();
 logan.Initialize();
 Assert.IsFalse(logan.IsValid(“abc”));
}

```

Именно изменение семантики как правило является причиной недовольства разработчиков при написании и сопровождении автономных тестов, поскольку объем изменений в тестах при изменении API
продуктового кода становится все больше и больше. В следующем
листинге показана более удобная для сопровождения версия этого
теста.

Листинг 8.3. Тест после рефакторинга – используется фабричный метод

```C#

[Test]
public void SemanticsChange()
{
 LogAnalyzer logan = MakeDefaultAnalyzer();
 Assert.IsFalse(logan.IsValid(“abc”));
}
public static LogAnalyzer MakeDefaultAnalyzer()
{
 LogAnalyzer analyzer = new LogAnalyzer();
 analyzer.Initialize();
 return analyzer;
}


```

В данном случае в переработанном тесте используется служебный
фабричный метод 1. Этот метод можно использовать и в других тестах. Если впоследствии семантика создания и инициализации объекта снова изменится, то не понадобится изменять все тесты, где создается объект; достаточно будет модифицировать лишь небольшой
служебный метод. Если вам наскучит создавать такие фабричные
методы, рекомендую обратить внимание на вспомогательный каркас
AutoFixture.
Я еще уделю этому каркасу внимание в приложение, но, если в двух
словах, то AutoFixture в числе прочего может использоваться как умная фабрика объектов, которая позволяет создать тестируемый объект, не особенно заботясь о структуре конструктора. Дополнительные
сведения об этом каркасе можно почерпнуть из статьи Google «String
Calculator Kata with AutoFixture» или на странице https://github.
com/AutoFixture/AutoFixture. Я еще не уверен, стану ли заядлым
сторонником этого каркаса (поскольку создать фабричный метод —
не такое большое дело), но познакомиться с ним и решить, нравится
он вам или нет, в любом случае стоит. При условии, что это не вредит
удобству чтения и сопровождения тестов, я вас удерживать не стану.
Ниже в этой главе мы познакомимся с другими приемами написания удобных для сопровождения тестов.

## Конфликтующие и недействительные тесты

Конфликт возникает, когда в продуктовом коде появляется новая
функция, прямо противоречащая тесту. Это означает, что тест теперь
находит не ошибку, а конфликтующие требования.
Рассмотрим простой пример. Пусть заказчик требует, чтобы
LogAnalyzer не принимал файлы, имя которых содержит меньше четырех букв. В этом случае анализатор должен возбуждать исключение. Функция реализована, и для нее написаны тесты.
Много позже заказчик приходит к выводу, что трехбуквенные имена файлов тоже имеют смысл и требует, чтобы они обрабатывались
особым образом. Эта функция добавлена и продуктовый код изменен. Мы написали новые тесты, учитывающие, что продуктовый код
больше не возбуждает исключение. Но изменив код, так чтобы они проходили, мы внезапно обнаруживаем, что старый тест (с трехбуквенным именем) проходить перестал. Он ожидает исключения, а его
нет. Если исправить продуктовый код, так чтобы этот тест проходил,
то перестанет проходить новый тест, проверяющий, что трехбуквенные имена обрабатываются специальным образом.
Такая ситуация «или-или», в которой может проходить только один
из двух тестов, служит признаком наличия конфликтующих тестов.
В таком случае сначала нужно убедиться, что конфликт действительно существует, а затем решить, какое требование оставить. После этого следует удалить (а не просто закомментировать) ставшее недействительным требование и тесты для него. (Серьезно, если я поймаю
кого-то на закомментаривании вместо удаления, то напишу целую
книгу под названием «Зачем Бог создал управление версиями».)
Конфликтующие тесты иногда позволяют выявить проблемы в
требованиях заказчика, и тогда заказчик должен решить, какое требование правильно.

## Переименование и рефакторинг тестов

Неудобочитаемый тест является скорее проблемой, чем решением.
Он может затемнить существо кода, и вы не поймете, какую ошибку
тест призван обнаруживать.
Встретив тест, имя которого расплывчато, сбивает с толку или
может быть сделано более удобным для сопровождения, изменяйте код теста (но не его базовую функциональность). В листинге 8.3
приведен пример такого рефакторинга теста с целью повышения
удобства сопровождения, в результате чего тест заодно стал и куда
более понятным.

## Устранение дублирующихся тестов

В случае командной разработки не редкость столкнуться с ситуацией, когда разные разработчики пишут тесты для проверки одной
и той же функциональности. Я не требую непременного устранения
дублирующихся тестов по двум причинам:
• чем больше (хороших) тестов, тем больше вероятность выловить ошибки;
• читая тесты, можно увидеть различные способы или семантику тестирования одной и той же функции.
Приведу несколько аргументов против сохранения дублирующихся тестов.

- Сопровождать несколько разных тестов одной и той же функциональности труднее.
- Одни тесты могут быть более качественными, чем другие, а
анализировать на предмет правильности нужно все.
- В случае ошибки в одном месте упадет сразу несколько тестов
(но это может и не считаться недостатком).
- Похожие тесты могут иметь разные имена или находиться в
разных классах.
- Чем больше тестов, тем сложнее сопровождение.

А вот аргументы за сохранение.

- В тестах могут быть мелкие различия, поэтому можно считать,
что они тестируют одну и ту же функциональность немного
по-разному. Возможно, при этом сложится более верное представление о тестируемом объекте.
- Одни тесты могут быть выразительнее других, поэтому наличие нескольких тестов может повысить удобочитаемость.

Выше я сказал, что не требую непременного устранения дублирующихся тестов, но обычно все же удаляю их; доводы против как правило перевешивают.

## Устранение логики из тестов

Шансы внести в тесты ошибки растут экспоненциально по мере добавления в них логики. Я видел, как многие тесты, которые по идее
должны быть простыми, становились динамическими монстрами
с изменяющейся логикой, генерацией случайных чисел, созданием
потоков и записью в файлы, монстрами, которые уже сами начинали
напоминать небольшие каркасы тестирования. Как это ни печально,
из-за наличия атрибута [Test] автор не считал, что в этих методах
могут быть ошибки, и не утруждал себя заботой об удобстве сопровождения. Такие тесты-монстры требовали на отладку и проверку
больше времени, чем экономили.
Но даже самые чудовищные монстры поначалу были маленькими.
Часто бывает, что какой-нибудь гуру в компании, глядя на тест, думает про себя: «А что если зациклить этот метод и подавать на вход
случайные числа? Ведь так мы точно выловим куда больше ошибок!»
Выловите, конечно, особенно в своих тестах. Ошибки в тестах сильнее всего раздражают программистов, потому что мы почти никогда
не подозреваем, что причина отказа теста – в самом тесте. Я не хочу
сказать, что такие тесты вовсе бесполезны. Я даже, наверное, сам их пишу. Но я бы не стал называть их автономными. Я бы сказал, что это
интеграционные тесты, потому что они слабо контролируют тестируемую сущность и доверять им на сто процентов я бы не стал (мы
разовьем эту тему в разделе об отделении интеграционных тестов от
автономных ниже).
Обнаружив в автономном тесте любую из следующих конструкций:

- предложения switch, if, else;
- циклы foreach, for, while,

знайте, что тест содержит логику, которой в нем быть не должно.

Тест, где имеется логика, обычно проверяет более одной вещи, что
не рекомендуется, потому что такой тест менее понятен и более хрупок. Кроме того, из-за наличия логики увеличивается сложность, которая может скрывать ошибку.
В общем случае автономный тест должен представлять собой последовательность вызовов методов и утверждений, без каких-либо
управляющих конструкций, в том число блоков try-catch. Все, что
более сложно, может стать причиной следующих проблем:

- тест труднее читать и понимать;
- тест трудно воспроизвести (представьте, что внезапно упал
тест с несколькими потоками или со случайными числами);
- выше вероятность того, что тест содержит ошибку или проверяет не то, что надо;
- тесту трудно придумать имя, потому что он делает несколько
вещей.

Как правило, тесты-монстры приходят на смену более простым
тестам, и это затрудняет поиск ошибок в продуктовом коде. Если уж
приходится создавать тест-монстр, то хотя бы добавляйте его в комплект, не удаляя существующие тесты, и помещайте в проект, созданный специально для интеграционных, а не автономных тестов.
Еще один вид логики, которой следует избегать в автономных тестах, иллюстрируется на следующем примере:

```C#

[Test]
public void ProductionLogicProblem()
{
 string user =”USER”;
 string greeting=”GREETING”;
 string actual = MessageBuilder.Build(user,greeting);
 Assert.AreEqual(user + greeting,actual);
}

```

Проблема здесь в том, что ожидаемый результат определяется в утверждении динамически. Это, пусть простая, но все же логика. Очень
может статься, что в тесте повторена логика продуктового кода –
вместе со всеми содержащимися в ней ошибками (потому что код и
тест писал один и тот же человек или потому что авторы кода и теста
оба имели превратное представление о поведении кода).
Это означает, что если ошибка в продуктовом коде существует и
повторена в тесте, то тест пройдет. В примере выше в ожидаемом значении в утверждении и в продуктовом коде пропущен пробел, поэтому тест проходит.
Было бы лучше «зашить» значения в код:

```C#

[Test]
public void ProductionLogicProblem()
{
 string actual = MessageBuilder.Build(“user”,”greeting”);
 Assert.AreEqual”user greeting”,actual);
}

```

Поскольку мы точно знаем, как должен выглядеть конечный результат, ничто не мешает зашить его в код. Теперь не имеет значения,
как этот результат получен, но если при его вычислении допущена
ошибка, то тест не пройдет. И из теста исчезла логика, которая могла
бы содержать ошибку.
Логику можно обнаружить не только в тестах, но и во вспомогательных методах, рукописных подделках и служебных классах для
тестирования. Помните – любая логика в этих местах серьезно осложняет чтение кода и повышает шансы на появление ошибки во
вспомогательном методе, используемом в тестах.
Если вы считаете, что по какой-то причине комплект тестов должен
содержать нетривиальную логику (хотя лично я сделал бы такие тесты
интеграционными, а не автономными), то, по крайней мере, включите
в тестовый проект парочку тестов, проверяющих логику служебных
методов. Тогда вам впоследствии не придется кусать локти.

## Тестирование только одного результата

Под результатом здесь понимается конечный результат единицы
работы: возвращаемое значение, изменение состояния системы или
обращение к стороннему объекту. Например, если в тесте высказываются утверждения о нескольких объектах, то, вероятно, тестируется более одного результата. То же самое имеет место, когда
проверяется, что объект возвращает правильное значение, и одновременно что состояние системы изменилось, так что объект стал
вести себя иначе.
Тестирование нескольких результатов кажется безобидным, пока
вы не задумаетесь о том, как назвать тест, или о том, что должно произойти, если первое утверждение не выполнено.
Выбор имени для теста – задача вроде бы простая, но если тестируется несколько результатов, то придумать хорошее имя, которое ясно
указывало бы, что именно тестируется, почти невозможно. Получается слишком общее имя, которое заставляет читателя изучать код теста (подробнее об этом будет сказано в разделе об удобочитаемости).
Если тестируется только один результат, то назвать тест легко.
Хуже то, что в большинстве каркасов автономного тестирования
(включая NUnit) ложное утверждение возбуждает специальное исключение, которое перехватывает исполнитель тестов. Если каркас
тестирования обнаружил такое исключение, считается, что тест не
прошел. К несчастью, исключения, по самой своей природе, препятствуют дальнейшему выполнению кода. В той строке, где возникло
исключение, происходит выход из метода. Пример приведен в листинге 8.4. Если первое утверждение ложно, то будет возбуждено исключение, а, значит, второе утверждение вообще никогда не проверяется, и мы не узнаем, изменилось ли поведение объекта, зависящее
от его состояния. Оба утверждения могут и должны рассматриваться
как разные требования, а потому могут и должны проверяться в разных тестах, следующих друг за другом.

Листинг 8.4. Тест с несколькими утверждениями

```C#

[Test]
public void IsValid_WhenValid_ReturnsTrueAndRemembersItLater()
{
 LogAnalyzer logan = MakeDefaultAnalyzer();
 Assert.IsTrue(logan.IsValid(“abc”));
 Assert.IsTrue(logan.WasLastCallValid);
}

```

Считайте невыполнение утверждения симптомом болезни. Чем
больше симптомов удается найти, тем легче диагностировать болезнь.
Утверждения, следующие за первым отказом, не проверяются, поэтому вы не увидите дополнительных симптомов, которые могли бы дать
ценные сведения для локализации и диагностики проблемы.
Тест, показанный в листинге 8.4, должен быть разбит на два теста с
подходящими именами.
Можно взглянуть на это и по-другому: если первое утверждение
ложно, то важен ли результат проверки следующего? Если да, то, вероятно, следует разбить тест на два.
Проверка нескольких результатов в одном автономном тесте лишь
увеличивает сложность, не давая почти ничего взамен. Дополнительные результаты следует проверять в отдельных независимых тестах,
чтобы было ясно, что именно не соответствует ожиданиям.

## Разделение автономных и интеграционных тестов

В главе 7 мы говорили о безопасной зеленой зоне для тестов. Я возвращаюсь к этому вопросу, потому что считаю его очень важным.
Если коллеги не верят, что ваши тесты будут работать быстро, давая
всякий раз один и тот же результат, то они вообще не станут их прогонять. Переработав тесты в этом направлении, вы сможете сделать
их заслуживающими больше доверия. Если ваши тесты находятся в
безопасной зеленой зоне, то другие разработчики склонны доверять
им в большей степени. Создать такую зеленую зону несложно – нужно лишь завести отдельный проект для автономных тестов и следить
за тем, чтобы туда попадали только тесты, работающие исключительно в памяти, повторяемые и дающие всякий раз один и тот же
результат.

## Проводите анализ кода, уделяя внимание покрытию кода

Что означает стопроцентное покрытие кода? Да ничего, если не сопровождается анализом кода. Возможно, генеральный директор потребовал, чтобы каждый сотрудник «обеспечил как минимум 95-процентное покрытие кода», и все будут делать то, что приказано. А в
тестах-то, быть может, и утверждений нет. Людям свойственно делать
то, что требуется для достижения метрики, на которой основана оценка их труда.
Что означает стопроцентное покрытие кода наряду с тестами и
анализом кода? А то, что весь мир в ваших руках. Если вы проводили анализ кода и анализ тестов и убедились, что тесты хороши и
покрывают весь код, значит, вы растянули страховочную сетку, которая предохранит от глупых ошибок, и одновременно дали возможность всем членам команды поделиться знаниями и не переставать
учиться.
Говоря «анализ кода», я не имею в виду равнодушное замечание
по поводу чужого кода, написанное кем-то на другом конце света,
которое автор увидит через три часа, когда критик уже ушел с работы.
Нет, говоря «анализ кода», я вижу двух людей, которые сидят и
беседуют, глядя на один и тот же кусок кода и внося в него изменения.
(Хотелось бы, чтобы они сидели бок о бок, но такие приложения для
удаленного диалога, как Skype и TeamViewer тоже подойдут.) В следующей главе я еще поделюсь своими впечатлениями о том, как захватывающе выглядят такие встречи, а сейчас просто запомните, что,
пренебрегая постоянным анализом кода и тестов вдвоем, вы теряете
замечательную возможность учиться и повышать продуктивность.
В таком случае сделайте все возможное, чтобы не лишать себя этого обязательного и непременного умения. Анализ кода – это техника
создания удобочитаемого высококачественного годами работающего
кода, которая позволит вам с уважением приветствовать свое отражение в зеркале по утрам.
Да не смотрите на меня так! Этот скептицизм только мешает вам
превратить свою нынешнюю работу в предмет мечтаний.
Однако же вернемся к разговору о покрытии кода.
Для обеспечения хорошего покрытия нового кода воспользуйтесь каким-нибудь автоматизированным инструментом (например,
dotCover компании JetBrains, OpenCover, NCover или Visual Studio
Pro). На данный момент мне больше нравится программа NCrunch,
которая в реальном времени дает представление о коде в терминах
красный-зеленый, изменяющееся по мере кодирования. Она стоит
денег, но зато и экономит деньги. Задача в том, чтобы найти достойный инструмент, освоить его в полной мере и выжать из него все до
капли, дабы покрытие кода больше никогда не было низким.
Если код покрыт меньше чем на 20 %, значит, очень многих тестов
не хватает, а ведь никогда не знаешь, что захочет сделать с твоим кодом разработчик, пришедший тебе на смену. Возможно, он попытается что-то оптимизировать или удалит какую-то важную строку. Если
нет теста, который в этом случае откажет, то ошибка может остаться
незамеченной.
Во время анализа кода и тестов можно также проводить ручные
проверки, это отличный способ спонтанного тестирования тестов.
Попробуйте закомментировать какую-нибудь строку или изменить
значение булевой переменной в продуктовом коде. Если все тесты
по-прежнему проходят, значит, каких-то тестов не хватает или тесты
проверяют не то, что нужно.
Добавив тест, который раньше отсутствовал, проверьте, то ли вы
добавили, выполнив следующие действия:
1. Закомментируйте продуктовый код, который, как вам кажется, не покрыт.
2. Прогоните все тесты.
3. Если все тесты проходят, значит, какого-то теста не хватает
или тестируется не то, что нужно. В противном случае должен существовать тест, который ожидает, что эта строка будет
выполнена или что окажется истинно какое-то утверждение,
вытекающее из выполнения этой строки. Тогда этот тест не
должен пройти.
4. Обнаружив недостающий тест, добавьте его. Закомментированный код таким и оставьте, при этом новый тест не должен
пройти – это докажет, что закомментированного кода действительно не хватает.
5. Раскомментируйте прежде закомментированный код.
6. Написанный тест теперь должен пройти. Вы нашли и добавили недостающий тест!
7. Если тест по-прежнему не проходит, значит, либо в тесте
ошибка, либо вы тестируете не то, что нужно. Измените тест,
так чтобы он прошел. Ваша задача добиться того, чтобы тест
не только проходил, когда должен проходить, но и падал, когда
должен падать. Чтобы убедиться в последнем, снова внесите
ошибку в продуктовый код (закомментировав в нем строку) и
проверьте, падает ли тест.

Чтобы повысить степень доверия к тесту, попробуйте заменить
различные параметры и внутренние переменные тестируемого метода константами (например, присвойте булевой переменной значение
true и посмотрите, что получится).
Но хитрость в том, чтобы вся эта возня с тестами не заняла слишком много времени, иначе она не окупится. Именно этому вопросу –
удобству сопровождения – посвящен следующий раздел.

## Написание удобных для сопровождения тестов

Удобство сопровождения – одна из основных проблем, стоящих перед большинством программистов, которые пишут автономные тесты. В конечном итоге сопровождать и понимать тесты становится все
труднее, и после малейшего изменения в системе то один, то другой
тест перестает проходить, даже если ошибок-то и нет. Со временем
появляется разрыв между вашим представлением о том, что делает
код, и тем, что он делает в действительности.
В этом разделе я поделюсь знаниями, которые достались мне нелегко – в процессе написания автономных тестов в составе различных команд. Сюда входит тестирование выполнения открытых контрактов, устранение дублирования и обеспечение изоляции тестов.

## Тестирование закрытых и защищенных методов

Закрытыми или защищенными методы обычно делаются не просто
так. Иногда причина в том, чтобы скрыть детали реализации и оставить возможность для последующего изменения реализации без
изменения заявленной функциональности. А иногда дело в безопасности и защите интеллектуальной собственности (к примеру, путем
запутывания).
Тестируя закрытый метод, мы тестируем выполнение внутреннего
системного контракта, который вполне может измениться. Внутренние контракты динамичны и подвержены изменению в процессе рефакторинга системы. Если такой контракт изменится, то тест может
отказать, потому что какая-то внутренняя операция стала выполняться по-другому, пусть даже заявленная функциональность системы осталась той же самой.
С точки зрения тестирования, нас должен интересовать только
открытый контракт (заявленная функциональность). Тестирование
закрытых методов может привести к отказу тестов, хотя заявленная
функциональность сохранилась.
Взгляните на это под таким углом зрения: закрытые методы существуют не без причины. Где-то в системе существует открытый метод,
который вызывает этот закрытый метод напрямую или опосредованно. Это означает, что любой закрытый метод является частью более крупной единицы работы, которая начинается в каком-то открытом
API и заканчивается одним из трех результатов: возвратом значения,
изменением состояния или обращением к стороннему объекту (или
всеми тремя сразу).
Но тогда, увидев закрытый метод, ищите открытую единицу работы, которая приведет к вызову этого метода. Если вы протестируете
один лишь закрытый метод и убедитесь, что он работает, это еще не
означает, что остальные части системы вызывают этот метод корректно или что они корректно обрабатывают его результаты. Возможно,
система правильно работает на внутреннем уровне, но открытые API
применяют всю эту скрытую красоту катастрофически неверно.
Если закрытый метод достоин тестирования, то, быть может, его
вообще стоит сделать открытым, статическим или хотя бы внутренним и определить открытый контракт, которого должны придерживаться все пользователи этого метода. А в некоторых случаях дизайн
станет чище, если поместить метод совсем в другой класс. Чуть ниже
мы рассмотрим оба подхода.
Означает ли это, что в кодовой базе вообще не должно остаться закрытых методов? Нет. Применяя TDD, мы обычно пишем тесты для
открытых методов, а позже эти открытые методы подвергаются рефакторингу с выделением более мелких закрытых методов. На всем
протяжении этого процесса тесты открытых методов проходят.

### Преобразование методов в открытые

Сделать метод открытым необязательно плохо. Возможно, это идет
вразрез с принципами объектно-ориентированного проектирования,
на которых вы воспитаны, но желание протестировать метод может
означать, что у этого метода имеется известное поведение или контракт с вызывающей стороной. Делая метод открытым, мы официально признаем этот факт. Оставляя метод закрытым, мы сообщаем всем
разработчикам, которые придут нам на смену, что реализацию этого
метода можно изменять, не заботясь о неизвестном коде, который может его использовать, потому что он имеет смысл только в составе
более крупного образования, которое и заключает контракт с вызывающей стороной.

### Перенос методов в новые классы

Если метод содержит много самостоятельной логики или пользуется состоянием класса, которое только к этому методу и относится,
то имеет смысл перенести метод в новый класс, который будет играть в системе отдельную роль. Затем этот класс можно тестировать независимо. Майкл Фэзерс в книге «Эффективная работа с унаследованным кодом» приводит интересные примеры такой техники, а Роберт
Мартин в «Чистом коде» рассказывает, как решить, действительно ли
эта идея хороша.

## Преобразование метода в статический

Если метод вообще не пользуется внутренним состоянием класса,
то разумно сделать его статическим. Такие методы тестировать гораздо проще, однако это решение также означает, что у метода имеется
открытый контракт, определяемый его именем.

## Преобразование метода во внутренний

 Если вы ни в коем случае не согласны раскрыть метод официально, то, быть может, стоит сделать его внутренним и задать атрибут
[InternalsVisibleTo(“TestAssembly”)] для сборки с продуктовым кодом – тогда тесты все же смогут вызывать этот метод. Мне это
не нравится, но иногда другого выбора не остается (то ли из соображений безопасности, то ли из-за отсутствия контроля над проектом
программы, то ли еще по какой-то причине).
Сделав метод внутренним, вы отнюдь не сделаете тесты более
удобными для сопровождения, потому что у кодировщика может
сложиться впечатление, что такой метод разрешено беспрепятственно изменять. Делая же метод частью явного открытого контракта, вы
можете быть уверены, что программист, которому придется его изменять, точно знает – метод реально используется и нарушать контракт
нельзя.
В версиях Visual Studio до 2012 была возможность создать закрытый акцессор – генерируемый Visual Studio класс-обертку, который с
помощью отражения вызывал закрытый метод. Не пользуйтесь этой
возможностью. Получающийся в результате код трудно сопровождать и нелегко понять по прошествии некоторого времени. Вообще,
лучше избегать любых инструментов, которые обещают сгенерировать за вас автономные тесты или еще что-нибудь, относящееся к тестированию, – если только нет никакого другого выбора.
Удаление метода – не лучшее решение, потому что он используется
и в продуктовом коде. В противном случае вообще не было бы причины писать тесты.
Еще один способ сделать код более удобным для сопровождения –
устранить дублирование тестов.

## Устранение дублирования

Дублирование в автономных тестах может навредить разработчикам
ничуть не меньше, чем дублирование в продуктовом коде (а то и больше). Принцип DRY относится к коду тестов в той же мере, что и к
продуктовому. Дублирование означает, что придется вносить больше
изменений, когда изменяется что-то в тестируемом коде. Простое
изменение конструктора или семантики использования класса может
оказать огромное влияние на тесты, в которых много дублирующегося
кода. Чтобы понять, почему это так, рассмотрим простой пример

Листинг 8.5. Тестируемый класс и тест, в котором он используется

```C#

public class LogAnalyzer
{
 public bool IsValid(string %leName)
 {
 if (%leName.Length < 8)
 {
 return true;
 }
 return false;
 }
}
[TestFixture]
public class LogAnalyzerTestsMaintainable
{
 [Test]
 public void IsValid_LengthBiggerThan8_IsFalse()
 {
 LogAnalyzer logan = new LogAnalyzer();
 bool valid = logan.IsValid(“123456789”);
 Assert.IsFalse(valid);
 }
}

```
Тест в нижней части листинга 8.5 кажется совершенно нормальным,
но это лишь до поры – пока не появится еще один тест того же класса.
Теперь у нас есть два теста, показанных в следующем листинге.

Листинг 8.6. Два теста, содержащих дублирование

```C#

[Test]
public void IsValid_LengthBiggerThan8_IsFalse()

{
 LogAnalyzer logan = new LogAnalyzer();
 bool valid = logan.IsValid(“123456789”);
 Assert.IsFalse(valid);
}
[Test]
public void IsValid_LengthSmallerThan8_IsTrue()
{
 LogAnalyzer logan = new LogAnalyzer();
 bool valid = logan.IsValid(“1234567”);
 Assert.IsTrue(valid);
}

```

Что не так с этими тестами? Основная проблема в том, что если
способ использования LogAnalyzer (его семантика) изменится, то
тесты придется сопровождать по отдельности, т. е. работы будет больше. В следующем листинге приведен пример такого изменения.

Листинг 8.7. Семантика LogAnalyzer изменилась – теперь требуется
инициализация

```C#

public class LogAnalyzer
{
 private bool initialized=false;
 public bool IsValid(string %leName)
 {
 if(!initialized)
 {
 throw new NotInitializedException(
 "" analyzer.Initialize()!”);
 }
 if (%leName.Length < 8)
 {
 return true;
 }
 return false;
 }
 public void Initialize()
 {
 // 
 ...
 initialized=true;
 }
}

```

Теперь оба теста в листинге 8.6 не пройдут, потому что в них не вызван метод Initialize(). Так как налицо дублирование кода (в обоих тестах создается экземпляр класса), то придется внести изменения
в каждый тест.
Можно провести рефакторинг тестов и устранить дублирование, создавая экземпляр LogAnalyzer в методе CreateDefaultAnalyzer(),
который будут вызывать оба теста. Можно также перенести создание
и инициализацию в новый метод подготовки, включив его в тестовый
класс.


## Устранение дублирование с помощью  вспомогательного метода

 В листинге 8.8 показано, как сделать тесты более удобными для
сопровождения, написав общий фабричный метод, который создает экземпляр LogAnalyzer по умолчанию. В предположении, что
все тесты пользуются этим методом, можно поместить в него вызов
Initialize(), тогда не придется изменять все тесты, добавляя в них
обращение к Initialize().

Листинг 8.8. Включение вызова Initialize() в фабричный метод

```c#

[Test]
public void IsValid_LengthBiggerThan8_IsFalse()
{
 LogAnalyzer logan = GetNewAnalyzer();
 bool valid = logan.IsValid(“123456789”);
 Assert.IsFalse(valid);
}
[Test]
public void IsValid_LengthSmallerThan8_IsTrue()
{
 LogAnalyzer logan = GetNewAnalyzer();
 bool valid = logan.IsValid(“1234567”);
 Assert.IsTrue(valid);
}
private LogAnalyzer GetNewAnalyzer()
{

  LogAnalyzer analyzer = new LogAnalyzer();
 analyzer.Initialize();
 return analyzer;
}


```

Фабричные методы – не единственный способ устранить дублирование в тестах, как станет ясно из следующего раздела.

## Устранение дублирования с помощью атрибута [SetUp]

Инициализировать LogAnalyzer можно и в методе Setup(), как
показано ниже.

Листинг 8.9. Использование метода подготовки для устранения
дублирования

```c#

[SetUp]
public void Setup()
{
 logan=new LogAnalyzer();
 logan.Initialize();
}
private LogAnalyzer logan= null;
[Test]
public void IsValid_LengthBiggerThan8_IsFalse()
{
 bool valid = logan.IsValid(“123456789”);
 Assert.IsFalse(valid);
}
[Test]
public void IsValid_LengthSmallerThan8_IsTrue()
{
 bool valid = logan.IsValid(“1234567”);
 Assert.IsTrue(valid);
}

```

При таком подходе в тестах даже не нужна строка, где создается
объект анализатора; до начала каждого теста создается новый экземпляр класса LogAnalyzer, после чего для него вызывается метод
Initialize(). Однако остерегайтесь: использовать метод подготовки для устранения дублирования не всегда разумно, как я объясню в
следующем разделе.

## Применение методов подготовки без усложнения сопровождения

 Метод Setup() использовать просто. Пожалуй, даже слишком просто – настолько, что разработчики применяют его и в тех случаях, на
которые он не рассчитан. И расплачиваются за это тестами, которые
неудобно читать и сопровождать.
Кроме того, у методов подготовки есть ограничения, которые можно обойти с помощью простых вспомогательных методов.
- Методы подготовки полезны только для инициализации.
- Методы подготовки – не всегда оптимальное средство для
устранения дублирования. Дублирование не обязательно сводится к созданию и инициализации новых объектов. Иногда
требуется устранить дублирование в утверждениях
- Методы подготовки не принимают параметры и не возвращают значение.
- Методы подготовки нельзя использовать в качестве фабричных
методов, возвращающих значение. Они вызываются до запуска
теста, поэтому должны быть более общими. Иногда тесту требуется запросить что-то конкретное или вызвать общий код с параметром, уникальным для данного теста (к примеру, получить
объект и присвоить его свойству определенное значение).
- Методы подготовки должны содержать лишь код, относящийся ко всем тестам в данном тестовом классе, иначе будет трудно понять, что метод делает.

Перечислив основные ограничения методов подготовки, посмотрим, как разработчики пытаются обойти их, стремясь во что бы то ни
стало использовать именно методы подготовки, а не вспомогательные методы. Можно привести следующие примеры неправильного
использования:

- инициализация в методах подготовки объектов, которые используются только в некоторых тестах из одного класса;
- написание длинного и малопонятного кода подготовки;
- настройка в методе подготовки поддельных объектов.

Рассмотрим эти примеры по очереди.

## Инициализация объектов, которые используются только в некоторых тестах

Это смертный грех. Предавшись ему, вы серьезно усложните не
только сопровождение, но даже чтение тестов, потому что метод под готовки очень быстро наполняется объектами, относящимися лишь к
некоторым тестам. В листинге ниже показано, во что может превратиться тестовый класс, в котором объект FileInfo инициализируется в методе подготовки, но используется только в одном тесте.

Листинг 8.10. Плохо реализованный метод Setup()

```c#

[SetUp]
public void Setup()
{
 logan=new LogAnalyzer();
 logan.Initialize();
 %leInfo=new FileInfo(“c:\\someFile.txt”);
}
private FileInfo %leInfo = null;
private LogAnalyzer logan = null;
[Test]
public void IsValid_LengthBiggerThan8_IsFalse()
{
 bool valid = logan.IsValid(“123456789”);
 Assert.IsFalse(valid);
}
[Test]
public void IsValid_BadFileInfoInput_returnsFalse()
{
 bool valid = logan.IsValid(%leInfo);
 Assert.IsFalse(valid);
}
[Test]
public void IsValid_LengthSmallerThan8_IsTrue()
{
 bool valid = logan.IsValid(“1234567”);
 Assert.IsTrue(valid);
}
private LogAnalyzer GetNewAnalyzer()
{
 ...
}

```

Почему этот метод подготовки плохо пригоден для сопровождения? Дело вот в чем – впервые видя тесты и пытаясь понять, как они
работают, читатель ведет себя следующим образом:
1. Изучает метод подготовки и смотрит, что в нем инициализируется.
2. Делает предположение, что инициализированные переменные
используются во всех тестах.
3. Позднее обнаруживает, что это предположение ложно, и снова,
уже более внимательно, просматривает тесты, чтобы понять,
где используются объекты, могущие стать источником проблем.
4. Углубляется в код теста без достаточных оснований, затрачивая больше времени и сил, чтобы понять, что делает код.

Всегда, когда пишете тесты, ставьте себя на место читателя. Представьте, что вы впервые видите код. Заботьтесь о читателе, не раздражайте его.

## Длинный и малопонятный код подготовки

 Поскольку метод подготовки – единственное место в тестовом
классе, где можно провести инициализацию, разработчики стараются инициализировать там как можно больше объектов, из-за чего
понятность кода неизбежно страдает. Возможное решение – завести
небольшие вспомогательные методы, вызываемые из метода подготовки для инициализации отдельных объектов. Рефакторинг метода
подготовки – вообще удачная мысль, потому что чем понятнее этот
метод, тем понятнее и весь тестовый класс.
Однако существует тонкая грань, за которой чрезмерное увлечение рефакторингом вредит удобочитаемости. Где она проходит, вопрос субъективный. Но вы должны следить, чтобы код не становился
непонятным. Я рекомендую во время рефакторинга интересоваться
мнением партнера. Все мы подпадаем под чары собственного кода,
поэтому вторая пара глаз, наблюдающая за рефакторингом, может
привнести объективный взгляд. Анализ кода (теста) коллегами постфактум – тоже вещь полезная, но не настолько, как критика в процессе работы.

## Настройка поддельных объектов в методе подготовки

Прошу вас – никогда не настраивайте подделки в методе подготовки. Это сильно затрудняет чтение и сопровождение тестов.
Я предпочитаю в каждом тесте создавать нужные заглушки и подставки, вызывая вспомогательные методы, тогда читатель будет точно знать, что происходит, не перескакивая глазами от теста к методу подготовки и обратно, чтобы составить полную картину.

## Отказ от методов подготовки

Я перестал использовать методы подготовки в своих тестах. Это
пережиток времен, когда считалось нормальным писать никуда не
годные, нечитаемые тесты. Те времена прошли. Тестовый код должен быть не менее красивым и чистым, чем продуктовый. Но если
продуктовый код выглядит ужасно, не считайте это оправданием для
написания нечитаемых тестов. Пользуйтесь фабричными и вспомогательными методами – и всем станет лучше.
Если все тесты устроены одинаково, то методы подготовки можно с
успехом заменить параметризованными тестами ([TestCase] в NUnit,
[Theory] в XUnit.net, [УвыЗаПятьЛетМыЭтоТакИНеСделали] в
MSTest). Ладно, шутка не очень удачная, но в MSTest действительно
так и не появилось простой поддержки для этой функции.

## Принудительная изоляция тестов

Отсутствие изоляции – самая главная причина подозрительного отношения к тестам, с которой я сталкивался в процессе консультирования и работы над автономными тестами. Основная идея состоит в
том, что тест должен работать в собственном мирке, полностью изолированном от знания о существовании других тестов, которые делают нечто похожее или совершенно другое.

**Тест, который кричал караул**
В одном проекте, где я работал, были автономные тесты, которые вели
себя странно, и со временем всё «страньше и страньше». В один день тест
падал, а в следующие два дня проходил нормально. Потом снова падал,
по видимости совершенно случайно, а иногда проходил, даже если тестируемое поведение кода изменялось или удалялось. Дошло до того, что
разработчики говорили между собой: «Да нормально все. Проходит иногда – и ладно».
 Как выяснилось, из этого теста вызывался другой тест и, когда тот падал,
падал и этот.
 У нас ушло три дня, чтобы понять, в чем дело, – после того как мы месяц
мирились с ситуацией. Когда наконец тест заработал правильно, оказалось, что в коде уйма ошибок, на которые мы не обращали внимания, списывая их на ложноположительные результаты сбоящего теста. История о
мальчике, который кричал «волки», применима и к разработке программного обеспечения.


Если тесты плохо изолированы, они могут наступать друг другу
на пятки, отравляя вам жизнь, заставляя жалеть о том, что вы связались с этими чертовыми автономными тестами, и клясться никогда
больше этого не делать. Я такое наблюдал. Разработчики не ожидают
встретить ошибку в тестах, поэтому, когда проблема кроется именно
там, на ее поиск уходит очень много времени.
Существует несколько «запашков», которые могут навести на
мысль о нарушенной изоляции тестов.

* Ограничения на порядок тестов. Ожидается, что тесты должны
выполняться в определенном порядке или получать информацию из результатов прогона других тестов.
* Скрытый вызов тест. Один тест вызывает другой.
* Повреждение разделяемого состояния. Несколько тестов пользуются одной и той же переменной в памяти, не возвращая ее
в исходное состояние.
* Повреждение внешнего разделяемого состояния. Интеграционные тесты пользуются общими ресурсами, но не возвращают
их в исходное состояние.

Рассмотрим эти антипаттерны по очереди.

## Антипаттерн: ограничения на порядок тестов

Эта проблема возникает, когда при написании тестов предполагается наличие определенного состояния в памяти, во внешнем ресурсе
или в текущем тестовом классе – состояния, созданное в результате выполнения других тестов из того же класса, запущенных раньше
текущего. Беда в том, что на большинстве платформ тестирования
(в том числе NUnit, JUnit и MbUnit) порядок выполнения тестов не
определен, поэтому то, что проходит сегодня, может отказать завтра.
В следующем листинге показан тест класса LogAnalyzer, ожидающий, что предыдущий тест уже вызывал метод Initialize().

Листинг 8.11. Ограничения на порядок тестов: второй тест не пройдет,
если будет выполнен первым

```c#

[TestFixture]
public class IsolationsAntiPatterns
{
 private LogAnalyzer logan;
 [Test]
 public void CreateAnalyzer_BadFileName_ReturnsFalse()
 {

   logan = new LogAnalyzer();
 logan.Initialize();
 bool valid = logan.IsValid(“abc”);
 Assert.That(valid, Is.False);
 }
 [Test]
 public void CreateAnalyzer_GoodFileName_ReturnsTrue()
 {
 bool valid = logan.IsValid(“abcdefg”);
 Assert.That(valid, Is.True);
 }
}

```

Отсутствие изоляции тестов может приводить к самым разным проблемам.
* Тест может внезапно перестать работать после перехода на новую версию каркаса тестирования, в которой тесты выполняются в другом порядке.
* Прогон подмножества тестов может давать иные результаты,
чем прогон всех тестов или другого подмножества.
* Сопровождение тестов усложняется, потому что нужно помнить о том, как тесты взаимосвязаны и как каждый влияет на
общее состояние.
* Тесты могут проходить или падать по причинам, не связанным
с тестируемым кодом; например, из-за того, что перед данным
тестом прошел или не прошел какой-то другой, оставив ресурсы в неопределенном состоянии.
* Удаление или изменение одних тестов может повлиять на результаты других.
* Трудно придумать для тестов подходящие имена, потому что
они тестируют более одной функции.

Существуют две общих ошибки, ведущие к плохой изоляции тестов.

* Тестирование последовательности. Разработчик пишет тесты,
которые должны выполняться в определенном порядке, чтобы
проверить последовательность действий, то есть большой сценарий, состоящий из многих операций. Это может быть также
полный интеграционный тест, в котором каждый отдельный
тест представляет один шаг.
* Пренебрежение очисткой. Ленивый разработчик не возвращает состояние, которое могло измениться в ходе теста, к исходному виду, а другие разработчики – осознанно или неосознанно – пишут тесты, зависящие от этого дефекта.

Решать эти проблемы можно по-разному

* Тестирование последовательности. Вместо того чтобы писать
автономные тесты для проверки последовательности действий, подумайте об использовании какого-нибудь каркаса интеграционного тестирования, например FIT или FitNesse или
продукта, предназначенного для контроля качества, например
AutomatedQA или WinRunner.
* Пренебрежение очисткой. Если вы ленитесь очищать после
тестирования базу данных, файловую систему или объекты в
памяти, подумайте о смене профессии. Эта работа не для вас.

## Антипаттерн: скрытый вызов теста

В этом случае тест содержит один или несколько прямых обращений к другим тестам в том же или ином тестовом классе, что приводит к взаимозависимости тестов. В листинге ниже приведен тест
CreateAnalyzer_GoodNameAndBadNameUsage, который в конце вызывает другой тест, что создает зависимость между тестами и нарушает изоляцию обоих.

Листинг 8.12. Вызов одного теста из другого нарушает изоляцию
и вводит зависимость

```c#

[TestFixture]
public class HiddenTestCall
{
 private LogAnalyzer logan;
 [Test]
 public void CreateAnalyzer_GoodNameAndBadNameUsage()
 {
 logan = new LogAnalyzer();
 logan.Initialize();
 bool valid = logan.IsValid(“abc”);
 Assert.That(valid, Is.False);
 CreateAnalyzer_GoodFileName_ReturnsTrue();
 }
 [Test]

 public void CreateAnalyzer_GoodFileName_ReturnsTrue()
 {
 bool valid = logan.IsValid(“abcdefg”);
 Assert.That(valid, Is.True);
 }
}

```

Такого рода зависимость 1 может приводить к нескольким проблемам.

* Прогон подмножества тестов может давать иные результаты,
чем прогон всех тестов или другого подмножества.
* Сопровождение тестов усложняется, потому что нужно помнить о том, как тесты взаимосвязаны и как и когда они вызывают друг друга.
* Тесты могут проходить или падать по причинам, не связанным
с тестируемым кодом. Например, если один тест упал, то другой может также упасть или вообще не будет вызван. Может
также случиться, что другой тест оставил какие-то общие переменные в неопределенном состоянии.
* Тесты могут проходить или падать по причинам, не связанным
с тестируемым кодом. Например, если один тест упал, то другой может также упасть или вообще не будет вызван. Может
также случиться, что другой тест оставил какие-то общие переменные в неопределенном состоянии.
* Трудно придумать хорошее имя для теста, который вызывает
другие тесты.

Как возникает эта проблема?

* Тестирование последовательности. Разработчик пишет тесты,
которые должны выполняться в определенном порядке, чтобы
проверить последовательность действий, то есть большой сценарий, состоящий из многих операций. Это может быть также
полный интеграционный тест, в котором каждый отдельный
тест представляет один шаг
* Попытка устранить дублирование. Разработчик пытается
устранить дублирование в одних тестах путем вызова других
(в которых уже имеется код, который не хочется повторять).
* Пренебрежение разделением тестов. Ленивый разработчик не
нашел времени, чтобы создать отдельный тест и выполнить рефакторинг как положено, а вместо этого решил срезать угол и
просто вызвать другой тест.
Решения:

* Тестирование последовательности. Вместо того чтобы писать
автономные тесты для проверки последовательности действий, подумайте об использовании какого-нибудь каркаса интеграционного тестирования, например FIT или FitNesse или
продукта, предназначенного для контроля качества, например
AutomatedQA или WinRunner.
* Попытка устранить дублирование. Никогда не пытайтесь устранить дублирование путем вызова одного теста из другого.
Вы не даете вызываемому тесту шанса воспользоваться методами подготовки и очистки и по существу выполняете два теста в одном (поскольку вызывающий тест проверяет утверждение, содержащееся в вызываемом). Вместо этого вынесите
код, который не хотите писать дважды, в отдельный метод и
вызывайте его из обоих тестов.
* Пренебрежение очисткой. Если вы ленитесь разделять тесты,
подумайте, сколько дополнительной работы вы на себя взваливаете. Попробуйте представить мир, в котором тест, который вы сейчас пишете, единственный в системе, так что зависеть ему не от кого.

## Антипаттерн: повреждение разделяемого состояния

Этот антипаттерн проявляется двумя независимыми способами.
* Тест изменяет разделяемые ресурсы (в памяти или внешние,
например базу данных, файловую систему и т. д.) и не откатывает сделанные изменения.
* Тест не устанавливает необходимое ему начальное состояние
до начала работы, считая, что оно уже кем-то установлено.

Симптомы в обоих случаях одинаковы, мы обсудим их ниже. Проблема в том, что повторяемость поведения тестов зависит от некоторого состояния. Если тест не контролирует состояние, которое ожидает,
или другие тесты по какой-то причине повреждают это состояние, то
тест не сможет правильно работать, стабильно получая один и тот же
результат.
Допустим, имеется класс Person с простой функциональностью:
он хранит внутри себя список телефонов и умеет искать номер по начальным цифрам. В листинге ниже показаны два теста, которые не
очищают и не инициализируют объект Person.

Листинг 8.13. Повреждение разделяемого состояния тестом

```c#

[TestFixture]
public class SharedStateCorruption

{
 Person person = new Person();
 [Test]
 public void CreateAnalyzer_GoodFileName_ReturnsTrue()
 {
 person.AddNumber(“055-4556684(34)”);
 string found = person.FindPhoneStartingWith(“055”);
 Assert.AreEqual(“055-4556684(34)”, found);
 }
 [Test]
 public void FindPhoneStartingWith_NoNumbers_ReturnsNull()
 {
 string found = person.FindPhoneStartingWith(“0”);
 Assert.IsNull(found);
 }
}

```

Здесь второй тест (ожидающий, что будет возвращено значение
null) не пройдет, потому что предыдущий тест добавил телефон 1 в
экземпляр Person.
Такого рода проблема проявляется рядом симптомов.

* Прогон подмножества тестов может давать иные результаты,
чем прогон всех тестов или другого подмножества.
* Сопровождение тестов усложняется, потому что один тест может изменить состояние и тем самым нарушить работу других
тестов, не сознавая этого.
* Тесты могут проходить или падать по причинам, не связанным
с тестируемым кодом; например, из-за того, что перед данным
тестом какой-то другой не прошел и оставил неопределенное
разделяемое состояние или прошел, но не подчистил за собой.
* Изменение одних тестов может оказать влияние – на первый
взгляд, случайное – на исход других

Как возникает эта проблема?
* Пренебрежение установкой состояния в начале каждого теста. Разработчик не устанавливает состояние, необходимое
для работы теста, или предполагает, что оно уже установлено
правильно.
* Использование разделяемого состояния. Разработчик использует общее состояние в памяти или во внешнем ресурсе в нескольких тестах, не принимая мер предосторожности.
* Использование статических объектов в тестах. Разработчик
устанавливает статическое состояние, которое используется в
других тестах.

Решения:
* Пренебрежение установкой состояния в начале каждого теста. Это обязательно нужно делать при написании автономных
тестов. Либо пользуйтесь методом подготовки, либо вызывайте в начале каждого теста вспомогательный метод, который
гарантированно устанавливает ожидаемое состояние.
* Использование разделяемого состояния. Часто можно обойтись вообще без разделяемого состояния. Самое безопасное
решение – создавать новый объект в каждом тесте.
* Использование статических объектов в тестах. Если тесты
управляют статическим состоянием, то нужна особая осторожность. Не забывайте сбрасывать такое состояние в методе подготовке или очистки. Иногда более эффективно явно
вызывать из теста какой-нибудь вспомогательный метод, который сбрасывает статическое состояние. Если тестируются
объекты-одиночки (singleton), то имеет смысл включить в них
открытые или внутренние установщики свойств, чтобы тесты
могли сбросить объект в исходное состояние.

## Антипаттерн: повреждение внешнего разделяемого состояния

 Этот антипаттерн похож на повреждение разделяемого состояния
в памяти, но встречается при интеграционном тестировании.

* Тест изменяет внешние разделяемые ресурсы (например, базу
данных или файловую систему) и не откатывает сделанные изменения.
* Тест не устанавливает необходимое ему начальное состояние
до начала работы, считая, что оно уже кем-то установлено.

Поговорив об изоляции тестов, обратимся к вопросу о том, как
надо управлять утверждениями, чтобы получать полную информацию в случае отказа теста.

## Предотвращение нескольких утверждений о разных функциях

Чтобы понять, в чем состоит проблема нескольких функций, рассмотрим пример.

Листинг 8.14. Тест с несколькими утверждениями

```c#

[Test]
public void CheckVariousSumResultsOgnoringHigherThan1001()
{
 Assert.AreEqual(3, Sum(1001,1,2));
 Assert.AreEqual(3, Sum(1,1001,2));
 Assert.AreEqual(3, Sum(1,2,1001);
}

```

В этом методе находится несколько тестов. Можно сказать, что тестируются три разные функции.
Автор теста пытался сэкономить время и включил три теста в виде
трех простых утверждений. В чем тут проблема? В случае ложности утверждения возбуждается исключение (в NUnit возбуждается
специальное исключение AssertException, которое исполнитель
тестов перехватывает и интерпретирует как знак того, что текущий
тестовый метод не прошел). Раз утверждение возбудило исключение,
то все последующие строки метода не выполняются. Таким образом,
если ложным оказалось первое утверждение в листинге 8.14, то два
остальных вообще не выполнялись. Ну и что? Может, нас и не интересуют остальные утверждения, если хотя бы одно ложно? Может
быть. А может быть и так, что в каждом утверждении тестируется независимая функция приложения, и нам важно знать результаты всех
тестов, даже если какой-то один не прошел.

Существует несколько способов достичь поставленной цели:
* создать свой тест для каждого утверждения;
* воспользоваться параметризованными тестами;
* обернуть вызов каждого утверждения блоком try-catch


Почему так существенно, что некоторые утверждения
не проверялись?
Если ложным оказалось только одно утверждение, то мы никогда не узнаем, истинны другие утверждения в том же тестовом методе или нет.
Возможно, вы думаете, что знаете, но до проверки утверждения это не
более чем предположение. Видя только часть картины, человек склонен
выносить о состоянии системы суждения, которые могут оказаться неверными. Чем больше у нас информации обо всех утверждениях – истинных
или ложных, – тем лучше мы вооружены для ответа на вопрос, в каком
месте системы может находиться ошибка, а в каком не может.
 Это относится только к утверждениям о нескольких функциях. Если же
вы проверяете, что некий человек зовется X, имеет от роду Y лет и т. д.,
то сказанное выше несущественно, потому что коль скоро одно утверждение оказалось ложно, остальные нас уже не интересуют. Однако заинтересовали бы, если бы ожидаемое действие имело несколько конечных
результатов. Например, возвращало бы число 3 и изменяло бы состояние
системы. То и другое – функции, которые должны работать независимо от
других функций.
 Мне доводилось охотиться за призраками ошибок, которые не желали
проявляться, потому что ложным оказывалось только одно из нескольких
утверждений. Если бы я дал себе труд проверить истинность остальных
утверждений, то понял бы, что ошибка совсем в другом месте. Иногда
программист находит «якобы ошибку», но, исправив ее, обнаруживает,
что утверждение, которое раньше было ложным, стало истинным, зато
перестали выполняться (или продолжают не выполняться) другие утверждения в том же тесте. Бывает, что мы не видим проблему во всей полноте, а исправление частичных проявлений только вносит в систему новые
ошибки, которые станут видны, лишь если известны результаты проверки
всех утверждений.
 Поэтому так важно, чтобы при тестировании нескольких функций проверялись все утверждения, даже если какие-то из них оказываются ложными. В большинстве случаев для этого лучше включать в каждый тест
только одно утверждение.

## Использование параметризованных тестов

И xUnit.net, и NUnit поддерживают так называемые параметризованные тесты с помощью атрибута [TestCase]. В листинге ниже
показано, как можно использовать несколько атрибутов [TestCase],
чтобы прогнать один и тот же тест с разными параметрами, ограничившись всего одним методом. Отметим, что в NUnit атрибут
[TestCase] заменяет атрибут [Test].

Листинг 8.15. Тот же тестовый класс с параметризованными тестами

```c#

[TestCase(1001,1,2,3)]
[TestCase (1,1001,2,3)]
[TestCase (1,2,1001,3)]
public void Sum_HigherThan1000_Ignored(int x, int y, int z, int expected)
{
 Assert.AreEqual(expected, Sum(x, y, z));
}

```

Параметризованные тестовые методы в NUnit и xUnit.net отличаются от обычных тем, что могут принимать параметры. В NUnit следует также снабдить тестовый метод по меньшей мере одним атрибутом
[TestCase] вместо [Test]. Этот атрибут принимает произвольное
число параметров, которые во время выполнения сопоставляются с
параметрами, указанными в сигнатуре тестового метода.

В листинге 8.15 тест ожидает четыре аргумента. В утверждении первые три аргумента выступают в роли параметров, а последний – в роли ожидаемого значения. Таким образом, появляется возможность
декларативно описать тест с различными исходными данными.
Но самое главное – если один из тестов, заданных с помощью атрибутов [TestCase], не проходит, то остальные все равно выполняются,
поэтому мы видим полную картину «прошел – не прошел».

## Обертывание блоком try-catch

Некоторые считают допустимым погрузить каждое утверждение в
свой блок try-catch, перехватить исключение, напечатать информацию о нем на консоли, а затем перейти к следующему предложению.
Таким образом обходится проблема исключений в тестах. Я полагаю,
что параметризованные тесты – более правильный способ достижения той же цели.
Итак, вы теперь знаете, как избежать в одном тесте нескольких утверждений о разных функциях. Давайте поговорим о тестировании
разных сторон одного объекта.

## Сравнение объектов

Вот еще один пример теста с несколькими утверждениями, но на этот
раз мы не пытаемся втиснуть несколько логических тестов в один,
а хотим проверить различные аспекты одного и того же состояния.
Если какая-то проверка закончится неудачно, мы хотим узнать об
этом.

Листинг 8.16. Проверка нескольких сторон одного объекта в одном тесте

```c#

[Test]
public void Analyze_SimpleStringLine_UsesDefaulTabDelimiterToParseFields()
{
 LogAnalyzer log = new LogAnalyzer();
 AnalyzedOutput output = log.Analyze(“10:05\tOpen\tRoy”);
 Assert.AreEqual(1,output.LineCount);
 Assert.AreEqual(“10:05”,output.GetLine(1)[0]);
 Assert.AreEqual(“Open”,output.GetLine(1)[1]);
 Assert.AreEqual(“Roy”,output.GetLine(1)[2]);
}

```

Здесь проверяется, что LogAnalyzer правильно разбирает входную строку, для чего каждое поле результата сравнивается отдельно. Все сравнения должны завершиться успешно, иначе будет считаться,
что тест не прошел.

## Повышение удобства сопровождения тестов
Ниже показано, как можно переработать тест из листинга 8.16, чтобы его было проще читать и сопровождать.

Листинг 8.17. Сравнение объектов вместо высказывания нескольких
утверждений

```c#

[Test]
public void Analyze_SimpleStringLine_UsesDefaulTabDelimiterToParseFields2()
{
 LogAnalyzer log = new LogAnalyzer();
 AnalyzedOutput expected = new AnalyzedOutput();
 expected.AddLine(“10:05”, “Open”, “Roy”);
 AnalyzedOutput output = log.Analyze(“10:05\tOpen\tRoy”);
 Assert.AreEqual(expected,output);
}

```

Вместо нескольких утверждений можно создать объект, задать
ожидаемые значения его свойств, а затем сравнить результат с ожидаемым объектом в одном утверждении. Такой код гораздо проще понять и в том числе установить, что имеется всего один логический
блок, а не несколько разрозненных тестов.

Внимание! Отметим, что такое сравнение возможно, лишь если в классе
сравниваемых объектов переопределен метод Equals(). Некоторые считают
это условие неприемлемым. Время от времени я такую технику применяю,
но могу пойти и первым путем. Решайте сами. Поскольку я использую
ReSharper, то мне достаточно нажать клавиши Alt+Insert, выбрать из меню
команду Generate Equality Members и – вуаля! – к моим услугам весь код,
необходимый для сравнения на равенство. Удобно.

## Переопределение метода ToString()

Другой подход состоит в том, чтобы переопределить метод
ToString() в классе сравниваемых объектов, так чтобы в случае отказа теста получать более понятные сообщения об ошибках. Вот, например, что мы увидим, если тест в листинге 8.17 не пройдет:

```c#
TestCase ‘AOUT.CH8.LogAn.Tests.MultipleAsserts
.Analyze_SimpleStringLine_UsesDefaulTabDelimiterToParseFields2’
failed:
Expected: <AOUT.CH789.LogAn.AnalyzedOutput>
But was: <AOUT.CH789.LogAn.AnalyzedOutput>
C:\GlobalShare\InSync\Book\Code\ARtOfUniTesting
\LogAn.Tests\MultipleAsserts.cs(41,0):
at AOUT.CH8.LogAn.Tests.MultipleAsserts
.Analyze_SimpleStringLine_UsesDefaulTabDelimiterToParseFields2()


```

Не очень полезно, правда?
Реализовав метод ToString() в классах AnalyzedOutput и
LineInfo (который является частью объектной модели), мы можем
получить от тестов более понятную выходную информацию. В листинге ниже показаны реализации ToString() в обоих тестируемых
классах и результаты, напечатанные тестом.


Листинг 8.18. Реализация метода ToString() в классах сравниваемых
объектов с целью получения более внятной выходной информации

```c#

// ToString AnalyzedOutput
public override string ToString()
{
 StringBuilder sb = new StringBuilder();
 foreach (LineInfo line in lines)
 {
 sb.Append(line.ToString());
 }
 return sb.ToString();
}
//  ToString  LineInfo
public override string ToString()
{
 StringBuilder sb = new StringBuilder();
 for (int i = 0; i < this.%elds.Length; i++)
 {
 sb.Append(this[i]);
 sb.Append(“,”);
 }
 return sb.ToString();
}
/// $^$8 \6'\&
------ Test started: Assembly: er.dll ------
TestCase ‘AOUT.CH8.LogAn.Tests.MultipleAsserts
.Analyze_SimpleStringLine_UsesDefaulTabDelimiterToParseFields2’
failed:
Expected: <10:05,Open,Roy,>
But was: <>
C:\GlobalShare\InSync\Book\Code\ARtOfUniTesting
\LogAn.Tests\MultipleAsserts.cs(41,0):
at AOUT.CH8.LogAn.Tests.MultipleAsserts
.Analyze_SimpleStringLine_UsesDefaulTabDelimiterToParseFields2()

```

Теперь вывод стал гораздо информативнее, и мы видим, что объекты не имеют между собой ничего общего. Благодаря внятной выходной информации становится легче разобраться, почему тест не
прошел, что, в свою очередь, упрощает сопровождение.
Затруднения при сопровождении могут возникнуть и потому, что
тесты слишком хрупкие из-за избыточного специфицирования.

## Предотвращение избыточного специфицирования

Избыточно специфицированным называется тест, который содержит
предположения о том, как должно быть реализовано внутреннее поведение тестируемой единицы работы (продуктовый код), а не просто
проверяет правильность конечного результата.
Вот как чаще всего проявляется избыточное специфицирование:
- в тесте высказывается утверждение о чисто внутреннем состоянии тестируемого объекта;
- в тесте используется несколько подставок;
- в тесте заглушки используются как подставки;
- в тесте предполагается определенный порядок следования или
производится точное сравнение строк, хотя это и не нужно.

Совет. Этот вопрос обсуждается также в книге Джерарда Мезароша «Шаблоны тестирования xUnit. Рефакторинг кода тестов».
Рассмотрим примеры избыточно специфицированных тестов.

## Проверка чисто внутреннего поведения

В следующем листинге приведен тест метода Initialize() из
класса LogAnalyzer, в котором проверяется только внутреннее состояние без какой-либо внешней функциональности.

Листинг 8.19. Избыточно специфицированный тест, в котором проверяется
чисто внутреннее поведение

```c#

[Test]
public void Initialize_WhenCalled_SetsDefaultDelimiterIsTabDelimiter()
{
 LogAnalyzer log = new LogAnalyzer();
 Assert.AreEqual(null,log.GetInternalDefaultDelimiter());

 log.Initialize();
 Assert.AreEqual(‘\t’, log.GetInternalDefaultDelimiter());
}

```

Этот тест избыточно специфицирован, потому что в нем проверяется лишь внутреннее состояние объекта LogAnalyzer. Раз это состояние внутреннее, то в будущем оно может измениться.
Автономные тесты должны проверять выполнение открытого контракта и открытую функциональность объекта. В данном случае тестируемый код не является частью открытого контракта или интерфейса.

## Использование заглушек как подставок

Использование подставок вместо заглушек – типичный случай
избыточного специфицирования. Рассмотрим пример. Пусть имеется репозиторий данных, который должен возвращать поддельные
данные тестам. Это заглушка. А что, если мы выскажем относительно
нее утверждение, проверяющее, что она действительно вызывалась?
Соответствующий код показан в листинге ниже.

Листинг 8.20. Избыточно специфицированный тест, в котором заглушка
используется как подставка

```c#

[Test]
public void IsLoginOK_UserDoesNotExist_ReturnsFalse()
{
 IDataRepository fakeData = A.Fake<IDataRepository>();
 A.CallTo(()=> fakeData.GetUserByName(A<string>.Ignored))
 .Returns(null);
 LoginManager login = new LoginManager(fakeData);
 bool result = login.IsLoginOK(“UserNameThatDoesNotExist”,”anypassword”);
 Assert.IsFalse(result);
 A.CallTo(()=>fakeData.GetUserByName(“UserNameThatDoesNotExist”))
 .MustHaveHappened();
}

```

Этот тест избыточно специфицирован, потому что в нем проверяется взаимодействие между заглушкой репозитория и LoginManager
(с помощью FakeItEasy). Тест должен дать тестируемому методу возможность работать по его внутреннему алгоритму, а проверить только
конечный результат. Тогда тест будет менее хрупким. А в таком виде,
как мы сейчас видим, тест перестанет работать, если мы захотим добавить какой-нибудь внутренний вызов или оптимизировать путем изменения параметров вызова. Коль скоро метод делает то, что от него
требуется, тесту должно быть все равно, вызывал он что-то внутри
себя или нет.
Будь тест написан правильно, последняя строка отсутствовала бы.
Еще один вид избыточного специфицирования тестов – чрезмерное количество допущений.

## Предположение об определенном порядке следования или точное сравнение,   когда это не нужно

Часто разработчики сравнивают возвращенное строковое значение
или свойство с фиксированной строкой, хотя требуется только совпадение части строки. Спросите себя: «Можно ли здесь использовать
string.Contains() вместо string.Equals()?».
То же самое относится к коллекциям и спискам. Гораздо лучше
проверять, что коллекция содержит ожидаемый элемент, чем утверждать, что элемент находится в определенной позиции (если, конечно,
именно это и ожидается).
Внеся эти мелкие поправки, вы можете быть уверены, что коль скоро строка или коллекция содержат ожидаемую часть, тест пройдет.
Даже если точный вид строки или порядок элементов в коллекции
изменяется, вам не придется вносить буквалистские изменения в
тест.
Теперь перейдем к третьему и последнему столпу хороших автономных тестов: удобочитаемости.

## Написание удобочитаемых тестов

Неудобочитаемые тесты почти бесполезны. Удобочитаемость – связующая нить между автором и беднягой, которому придется читать
тест через несколько месяцев. Тесты – это истории, которые вы рассказываете следующему поколению программистов, работающих над
проектом. Они говорят разработчику, из чего состоит приложение и с
чего оно начиналось.
В этом разделе мы поговорим о том, как сделать так, чтобы программисты, которые придут вслед за вами, смогли поддерживать написанный вами продуктовый код и тесты, понимая, что они делают и
куда смотреть.

У удобочитаемости есть несколько граней:
- именование автономных тестов;
- именование переменных;
- хорошие сообщения в утверждениях;
- отделение утверждений от действий.

Рассмотрим все по порядку.

## Именование автономных тестов

 Стандарты именования важны, поскольку предлагают правила и
шаблоны, подсказывающие, что вы должны рассказать о тесте. Имя
теста состоит из трех частей.

* Имя тестируемого метода. Это необходимо, чтобы можно
было легко понять, где искать тестируемую логику. Делая эту
часть первой, мы упрощаем навигацию и применение технологии Intellisense (если IDE ее поддерживает) в тестовом классе.
* Имя тестируемого метода. Это необходимо, чтобы можно
было легко понять, где искать тестируемую логику. Делая эту
часть первой, мы упрощаем навигацию и применение технологии Intellisense (если IDE ее поддерживает) в тестовом классе.
* Поведение, ожидаемое в данном сценарии. В этой части объясняется, что должен возвращать метод или как он должен себя
вести в контексте данного сценария: «Когда метод X вызывается со значением null, он должен делать Y».

Если убрать хотя бы одну часть имени, то читателю будет непонятно, что происходит, и он начнет изучать код теста. Ваша главная
цель – освободить своего преемника от необходимости читать код
теста, чтобы понять, что тестируется.
Обычно три части имени разделяют знаками подчеркивания, например: MethodUnderTest_Scenario_Behavior(). Ниже приведен
тест, в имени которого описанное соглашение соблюдается.

Листинг 8.21. Имя теста, состоящее из трех частей

[Test]
public void
AnalyzeFile_FileWith3LinesAndFileProvider_ReadsFileUsingProvider()
{
 //...
}

Этот метод тестирует метод AnalyzeFile , подавая ему на вход
файл из трех строчек и поставщик чтения файла. Ожидается, что
метод воспользуется поставщиком для чтения файла.

Если все разработчики будут придерживаться этого соглашения
об именовании, то новым членам команды будет проще войти в курс
дела и разобраться в тестах.

## Именование переменных

Принципы именования переменных в автономных тестах важны не
менее, а то и более, чем в продуктовом коде. Помимо основной функции – тестирования, тесты являются еще и одним из видов документации API. Давая переменным хорошие имена, вы помогаете читателям тестов максимально быстро понять, что вы пытаетесь доказать
(в отличие от того, что вы пытаетесь осуществить в продуктовом
коде).
В следующем листинге приведен пример плохо названного и плохо
написанного теста. Такой тест я называю «нечитаемым», потому что
не могу понять, какова его цель.

Листинг 8.22. Нечитаемое имя теста

```c#

[Test]
public void BadlyNamedTest()
{
 LogAnalyzer log = new LogAnalyzer();
 int result= log.GetLineCount(“abc.txt”);
 Assert.AreEqual(-100,result);
}

```

В данном случае в утверждении встречается какое-то магическое
число (-100), представляющее значение, о котором разработчик должен знать. Не имея осмысленного имени для этого числа, мы можем
только предполагать, что оно означает. Имя теста должно быть тут
помочь, но его – как бы помягче сказать? – следует немного подправить.

Так что такое 100? Признак какой-то ошибки? Нормальное возвращаемое значение? Тут у нас есть выбор:

* изменить дизайн API и возбуждать исключение вместо возврата -100 (в предположении, что 100 свидетельствует о наличии ошибки);
* сравнивать результат с именованной константой или удачно
названной переменной, как показано ниже.

Листинг 8.23. Более удобочитаемый вариант теста

```c#

[Test]
public void BadlyNamedTest()
{
 LogAnalyzer log = new LogAnalyzer();
 int result= log.GetLineCount(“abc.txt”);
 const int COULD_NOT_READ_FILE = -100;
 Assert.AreEqual(COULD_NOT_READ_FILE,result);
}

```

Код в листинге 8.23 гораздо лучше, так как легко понять смысл
возвращаемого значения.
Последняя часть теста – обычно утверждение, и мы должны выжать максимум пользы из содержащегося в нем сообщения. Если утверждение ложно, то первое, что увидит пользователь, – это напечатанное сообщение.

## Утверждения со смыслом

Не пишите свои сообщения в утверждениях. Прошу вас. Этот раздел
предназначен тем, кто считает абсолютно необходимым нестандартное сообщение, потому что тест без него ну никак не обойдется, а
сделать тест более понятным по-другому не получается. Придумать
хорошее сообщение в утверждении ничуть не проще, чем в исключении. Очень легко пойти по неверному пути, даже не сознавая этого, а
для людей, которые будут сообщение читать, разница огромна (в том
числе в плане временных затрат).

Запомните несколько советов о том, каким должно быть сообщение в утверждении.

* Не повторяйте то, что каркас тестирования и так выводит на консоль.
* Не повторяйте то, что ясно из имени теста.
* Если вам нечего сказать, не говорите ничего
* Напишите, что должно было произойти или что не произошло, и по возможности упомяните, когда это должно было произойти.

В листинге ниже приведен пример плохого сообщения в утверждении и показано, что печатается в результате.

Листинг 8.24. Плохое сообщение в утверждении, повторяющее то,
что каркас тестирования и так печатает

```c#

[Test]
public void BadAssertMessage()
{
 LogAnalyzer log = new LogAnalyzer();
 int result= log.GetLineCount(“abc.txt”);
 const int COULD_NOT_READ_FILE = -100;
 Assert.AreEqual(COULD_NOT_READ_FILE,result,
 “result was {0} instead of {1}”,
 result,COULD_NOT_READ_FILE);
}
// :
TestCase ‘AOUT.CH8.LogAn.Tests.Readable.BadAssertMessage’
failed:
 result was -1 instead of -100
 Expected: -100
 But was: -1
C:\GlobalShare\InSync\Book\Code
\ARtOfUniTesting\LogAn.Tests\Readable.cs(23,0)
: at AOUT.CH8.LogAn.Tests.Readable.BadAssertMessage()

```

Как видите, сообщение повторяется. Включенное в утверждение
сообщение не добавило ничего, кроме лишних слов, которые приходится читать. Было бы куда лучше ничего не выводить, а подумать о
хорошем имени для теста. Более внятное сообщение могло бы выглядеть так:

```c#

$Вызов GetLineCount() для несуществующего файла должен был вернуть COULD_NOT_READ_FILE.


```

Итак, все ваши сообщения теперь понятны. Самое время убедиться, что утверждение и вызов метода находятся в разных строках.

## Отделение утверждений от действий

 Этот раздел будет коротким, но от того не менее важным. Для повышения удобочитаемости не помещайте утверждение и вызов метода в
одно предложение.
В листинге 8.25 приведен хороший, а в листинге 8.26 – плохой пример.

Листинг 8.25. Отделение утверждения от его предмета, тест легко читается

```c#

[Test]
public void BadAssertMessage()
{
 // код
 int result= log.GetLineCount(“abc.txt”);
 Assert.AreEqual(COULD_NOT_READ_FILE,result);
}

```

Листинг 8.26. Утверждение и его предмет не разделены, тест читается
с трудом

```C#

[Test]
public void BadAssertMessage()
{
 // 
 Assert.AreEqual(COULD_NOT_READ_FILE,log.GetLineCount(“abc.txt”));
}
```

Видите разницу? Тест в листинге 8.26 понять гораздо труднее, потому что вызов метода GetLineCount() находится внутри утверждения.

##  Подготовка и очистка

 Методы подготовки и очистки в автономных тестах можно использовать до такой степени неправильно, что понять их будет невозможно.
Обычно метод подготовки подвержен этому злу больше, нежели метод очистки.
 Рассмотрим один пример злоупотребления. Если заглушки и подставки настраиваются в методе подготовки, значит, в самом тесте они
не настраиваются. Это, в свою очередь, означает, что читатель теста
может и не понять, что подставки вообще используются и чего тест
от них ожидает.
Тест станет гораздо понятнее, если инициализировать подставные
объекты в нем самом – там, где описываются ожидания. Если удобочитаемость для вас не пустой звук, то можете вынести создание подставок в отдельный вспомогательный метод, вызываемый из теста.
Тогда читатель теста будет точно знать, что настраивается, и ему не
придется заглядывать в несколько мест.

Совет. Я несколько раз писал полные тестовые классы вообще без метода
подготовки – только вспомогательные методы, вызываемые из каждого теста. Все ради удобства сопровождения. Эти классы до сих пор удобочитаемы
и сопровождаются.

## Выводы

Немногие разработчики с первой попытки начинают писать автономные тесты, заслуживающие доверия. Чтобы сделать все правильно,
нужны дисциплина и изобретательность. Свойство «заслуживает доверия» поначалу кажется трудноуловимым, но, поймав его, вы сразу
ощутите разницу.
Есть несколько способов создавать достойные доверия тесты, в
том числе оставлять в живых и актуализировать хорошие тесты, удаляя либо подвергая рефакторингу плохие. В этой главе мы обсудили
ряд таких способов. А также проблемы, возникающие внутри тестов:
наличие логики, тестирование сразу нескольких функций, простота
запуска и т. д. Чтобы собрать все воедино, требуется немалое искусство.
Если вы забудете все сказанное в этой главе, кроме одной-единственной мысли, то пусть это будет мысль о том, что тесты развиваются
и изменяются вместе с тестируемой системой.
Тема разработки удобных для сопровождения тестов в последние
годы привлекала немало внимания, но, как я уже сказал, она недостаточно раскрыта в литературе по автономному тестированию и
TDD – и не без причины. Я полагаю, что это будет следующий шаг
в изучении эволюции приемов автономного тестирования. Первый
шаг – приобретение начальных знаний (что такое автономный тест и
как его писать), он описывается во многих местах. Второй шаг – шлифовка техники, совершенствование всех граней написанного вами
кода и исследование других факторов, в том числе удобства чтения и
сопровождения. Этот шаг очень важен, и именно ему посвящена эта
глава (да и большая часть книги).
По существу, все просто: удобочитаемость идет рука об руку с
удобством сопровождения и доверием к тестам. Человек, который
может прочесть тесты, сможет также понять и сопровождать их, и будет доверять их результатам. Дойдя до этой стадии, вы будете готовы
взглянуть в лицо изменениям, и ничто не помешает вам модифицировать код, если он в этом нуждается, потому что вы сразу узнаете о
поломке.
В следующих главах мы взглянем на автономные тесты шире – как
на часть более крупной системы: поговорим об их месте в организации, а также о взаимосвязи с существующими системами и унаследованным кодом. Вы узнаете, что делает код тестопригодным, как
проектировать с учетом тестопригодности и как с помощью рефакторинга привести имеющийся код в тестопригодное состояние.

